{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install pandas scikit-learn xgboost imbalanced-learn seaborn matplotlib lightgbm category_encoders --quiet\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, GroupKFold\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import (accuracy_score, f1_score, confusion_matrix,\n",
        "                           classification_report, mean_squared_error, r2_score)\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "import joblib\n",
        "from category_encoders import TargetEncoder\n",
        "\n",
        "# =============================================\n",
        "# DATA LOADING & CLEANING (ENHANCED)\n",
        "# =============================================\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/cleaned_dataset.csv')\n",
        "\n",
        "# Standardize and clean categorical columns\n",
        "def clean_crop_name(name):\n",
        "    name = name.lower().strip()\n",
        "    replacements = {\n",
        "        'chilli': 'chili',\n",
        "        'pearl millet (bajra)': 'pearl millet',\n",
        "        'tur (pigeonpea)': 'pigeonpea',\n",
        "        'green gram': 'mung bean'\n",
        "    }\n",
        "    return replacements.get(name, name)\n",
        "\n",
        "df['crop'] = df['crop'].apply(clean_crop_name)\n",
        "df[['state', 'district', 'soil_type', 'month']] = df[['state', 'district', 'soil_type', 'month']].apply(lambda x: x.str.lower().str.strip())\n",
        "\n",
        "# Handle numeric columns\n",
        "num_cols = ['soil_ph', 'rainfall_mm', 'temperature_c']\n",
        "df[num_cols] = df[num_cols].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Drop duplicates & missing values\n",
        "df = df.drop_duplicates().dropna(subset=num_cols + ['crop'])\n",
        "\n",
        "# =============================================\n",
        "# CROP CLASS OPTIMIZATION (IMPROVED)\n",
        "# =============================================\n",
        "\n",
        "crop_categories = {\n",
        "    'cereals': [\n",
        "        'wheat', 'rice', 'maize', 'barley', 'sorghum', 'pearl millet', 'ragi', 'jowar'\n",
        "    ],\n",
        "    'pulses': [\n",
        "        'chickpea', 'urad dal', 'mung bean', 'lentil', 'pigeon pea', 'rajma',\n",
        "        'black-eyed pea', 'adzuki bean', 'green bean', 'cowpea', 'field bean',\n",
        "        'horse gram', 'lathyrus'\n",
        "    ],\n",
        "    'oilseeds': [\n",
        "        'mustard', 'sunflower', 'groundnut', 'sesame', 'castor', 'linseed', 'soybean', 'peanut'\n",
        "    ],\n",
        "    'vegetables': [\n",
        "        'tomato', 'potato', 'onion', 'brinjal', 'cabbage', 'cauliflower',\n",
        "        'pumpkin', 'okra', 'bottle gourd', 'cucumber', 'chili pepper', 'spinach',\n",
        "        'amaranth', 'carrot', 'bitter gourd', 'broccoli', 'lettuce', 'radish'\n",
        "    ],\n",
        "    'fruits': [\n",
        "        'mango', 'banana', 'orange', 'kinnow', 'lemon', 'lime', 'guava',\n",
        "        'watermelon', 'papaya', 'grapes', 'apple', 'pear', 'plum',\n",
        "        'litchi', 'pineapple', 'peach', 'cherry', 'jackfruit', 'grapefruit'\n",
        "    ],\n",
        "    'spices_and_condiments': [\n",
        "        'turmeric', 'coriander', 'ginger', 'garlic', 'cumin', 'black pepper',\n",
        "        'cardamom', 'tamarind', 'fenugreek'\n",
        "    ],\n",
        "    'plantation_crops': [\n",
        "        'tea', 'coffee', 'coconut', 'arecanut', 'cashew'\n",
        "    ],\n",
        "    'dryland_and_fiber_crops': [\n",
        "        'cotton', 'jute'\n",
        "    ],\n",
        "    'nuts': [\n",
        "        'almond', 'hazelnut', 'walnut'\n",
        "    ],\n",
        "    'medicinal_and_misc': [\n",
        "        'ashwagandha', 'moringa', 'betel leaf', 'tobacco'\n",
        "    ],\n",
        "    'tubers': [\n",
        "        'tapioca'\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Apply categorization and remove 'other' class\n",
        "df['crop_category'] = df['crop'].apply(lambda x: next((k for k, v in crop_categories.items() if x in v), None))\n",
        "df = df.dropna(subset=['crop_category'])  # Remove uncategorized crops\n",
        "\n",
        "# Only keep categories with sufficient samples\n",
        "min_samples = 50\n",
        "valid_categories = df['crop_category'].value_counts()[df['crop_category'].value_counts() >= min_samples].index\n",
        "df = df[df['crop_category'].isin(valid_categories)]\n",
        "\n",
        "# =============================================\n",
        "# FEATURE ENGINEERING (ENHANCED)\n",
        "# =============================================\n",
        "\n",
        "# Cyclical month encoding\n",
        "df['month_sin'] = np.sin(2 * np.pi * (pd.to_datetime(df['month'], format='%b').dt.month - 1)/12)\n",
        "df['month_cos'] = np.cos(2 * np.pi * (pd.to_datetime(df['month'], format='%b').dt.month - 1)/12)\n",
        "\n",
        "# Soil fertility indicator\n",
        "df['fertility_index'] = np.where(\n",
        "    (df['soil_ph'] > 6) & (df['soil_ph'] < 7.5) & (df['rainfall_mm'] > 500),\n",
        "    1, 0\n",
        ")\n",
        "\n",
        "# Add aggregated features\n",
        "df['district_month_avg_ph'] = df.groupby(['district', 'month'])['soil_ph'].transform('mean')\n",
        "df['district_month_avg_rain'] = df.groupby(['district', 'month'])['rainfall_mm'].transform('mean')\n",
        "\n",
        "# Growing Degree Days\n",
        "base_temp = 10\n",
        "df['gdd'] = np.maximum(df['temperature_c'] - base_temp, 0)\n",
        "\n",
        "# Rainfall seasonality\n",
        "df['is_monsoon'] = df['month'].isin(['jun', 'jul', 'aug', 'sep']).astype(int)\n",
        "\n",
        "# District encoding (frequency-based)\n",
        "district_encoding = df.groupby('district')['crop_category'].agg(lambda x: x.value_counts().index[0])\n",
        "df['district_encoded'] = df['district'].map(district_encoding)\n",
        "\n",
        "# =============================================\n",
        "# CROP CATEGORY RECOMMENDATION MODEL (IMPROVED)\n",
        "# =============================================\n",
        "\n",
        "# Features & Target\n",
        "features = [\n",
        "    'soil_type', 'soil_ph', 'temperature_c', 'rainfall_mm',\n",
        "    'month_sin', 'month_cos', 'fertility_index',\n",
        "    'district_month_avg_ph', 'district_month_avg_rain',\n",
        "    'gdd', 'is_monsoon', 'district_encoded'\n",
        "]\n",
        "X = df[features]\n",
        "y = df['crop_category']\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Train-test split with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "# Preprocessing with TargetEncoder\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', TargetEncoder(), ['soil_type', 'district_encoded']),\n",
        "        ('num', StandardScaler(), [\n",
        "            'soil_ph', 'temperature_c', 'rainfall_mm',\n",
        "            'month_sin', 'month_cos', 'fertility_index',\n",
        "            'district_month_avg_ph', 'district_month_avg_rain',\n",
        "            'gdd', 'is_monsoon'\n",
        "        ])\n",
        "    ])\n",
        "\n",
        "# Model Pipeline with LightGBM (better for categoricals)\n",
        "model = ImbPipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('sampler', SMOTE(random_state=42, sampling_strategy='not majority')),\n",
        "    ('classifier', LGBMClassifier(\n",
        "        random_state=42,\n",
        "        n_estimators=300,\n",
        "        max_depth=5,\n",
        "        learning_rate=0.05,\n",
        "        colsample_bytree=0.8,\n",
        "        subsample=0.8,\n",
        "        class_weight='balanced'\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train with cross-validation\n",
        "print(\"Training Improved Crop Category Recommendation Model...\")\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"\\n--- Improved Crop Category Recommendation Model ---\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
        "print(f\"Weighted F1: {f1_score(y_test, y_pred, average='weighted'):.2f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "# Feature Importance\n",
        "try:\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    feature_importances = model.named_steps['classifier'].feature_importances_\n",
        "    feature_names = features  # Simplified for this example\n",
        "    pd.Series(feature_importances, index=feature_names).sort_values().plot(kind='barh')\n",
        "    plt.title('Feature Importance')\n",
        "    plt.show()\n",
        "except Exception as e:\n",
        "    print(f\"Could not plot feature importance: {str(e)}\")\n",
        "\n",
        "# Save artifacts\n",
        "joblib.dump(model, 'improved_crop_category_model.pkl')\n",
        "joblib.dump(label_encoder, 'crop_category_encoder.pkl')\n",
        "\n",
        "# =============================================\n",
        "# SOIL pH PREDICTION MODEL (VALIDATED)\n",
        "# =============================================\n",
        "\n",
        "# Check if soil pH prediction is actually needed\n",
        "if df['soil_ph'].nunique() > 10:  # Only proceed if sufficient variability\n",
        "    # Features & Target\n",
        "    features_ph = ['state', 'district', 'month_sin', 'month_cos']\n",
        "    X_ph = df[features_ph]\n",
        "    y_ph = df['soil_ph']\n",
        "\n",
        "    # Train-test split with district grouping\n",
        "    groups = df['district']  # For GroupKFold\n",
        "    X_train_ph, X_test_ph, y_train_ph, y_test_ph = train_test_split(\n",
        "        X_ph, y_ph, test_size=0.2, random_state=42, stratify=groups\n",
        "    )\n",
        "\n",
        "    # Preprocessing\n",
        "    preprocessor_ph = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('cat', OneHotEncoder(handle_unknown='ignore'), ['state', 'district'])\n",
        "        ])\n",
        "\n",
        "    # Model Pipeline\n",
        "    model_ph = Pipeline([\n",
        "        ('preprocessor', preprocessor_ph),\n",
        "        ('regressor', XGBRegressor(\n",
        "            random_state=42,\n",
        "            n_estimators=100,\n",
        "            max_depth=3\n",
        "        ))\n",
        "    ])\n",
        "\n",
        "    # Train with grouped cross-validation\n",
        "    print(\"\\nTraining Soil pH Model...\")\n",
        "    cv = GroupKFold(n_splits=5)\n",
        "    model_ph.fit(X_train_ph, y_train_ph)\n",
        "\n",
        "    # Evaluation\n",
        "    y_pred_ph = model_ph.predict(X_test_ph)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test_ph, y_pred_ph))\n",
        "    print(\"\\n--- Soil pH Prediction Model ---\")\n",
        "    print(f\"RMSE: {rmse:.2f}\")\n",
        "    print(f\"R²: {r2_score(y_test_ph, y_pred_ph):.2f}\")\n",
        "\n",
        "    # Save model\n",
        "    joblib.dump(model_ph, 'soil_ph_model.pkl')\n",
        "else:\n",
        "    print(\"\\nSoil pH shows insufficient variability - skipping regression model\")\n",
        "\n",
        "# =============================================\n",
        "# PREDICTION EXAMPLES (FIXED)\n",
        "# =============================================\n",
        "\n",
        "# Example 1: Crop Prediction\n",
        "sample_data = pd.DataFrame({\n",
        "    'soil_type': ['vertisols'],\n",
        "    'soil_ph': [6.5],\n",
        "    'temperature_c': [22],\n",
        "    'rainfall_mm': [15],\n",
        "    'month_sin': [np.sin(2 * np.pi * (1-1)/12)],  # January\n",
        "    'month_cos': [np.cos(2 * np.pi * (1-1)/12)],\n",
        "    'fertility_index': [1],\n",
        "    'district_month_avg_ph': [6.8],\n",
        "    'district_month_avg_rain': [12],\n",
        "    'gdd': [12],\n",
        "    'is_monsoon': [0],\n",
        "    'district_encoded': ['cereals']  # Most common in district\n",
        "})\n",
        "\n",
        "# Ensure sample data has same columns as training data in correct order\n",
        "sample_data_fixed = pd.DataFrame(sample_data, columns=X_train.columns)\n",
        "assert list(sample_data_fixed.columns) == list(X_train.columns), \"Mismatch in feature names!\"\n",
        "\n",
        "predicted_category = label_encoder.inverse_transform(model.predict(sample_data_fixed))[0]\n",
        "print(f\"\\nRecommended crop category: {predicted_category}\")\n",
        "print(f\"Potential crops in this category: {', '.join(crop_categories.get(predicted_category, []))}\")\n",
        "\n",
        "# Example 2: Soil pH Prediction (if model exists)\n",
        "if 'model_ph' in locals():\n",
        "    sample_ph_data = pd.DataFrame({\n",
        "        'state': ['chhattisgarh'],\n",
        "        'district': ['durg'],\n",
        "        'month_sin': [np.sin(2 * np.pi * (1-1)/12)],  # January\n",
        "        'month_cos': [np.cos(2 * np.pi * (1-1)/12)]\n",
        "    })\n",
        "    # Ensure columns match training data\n",
        "    sample_ph_data_fixed = pd.DataFrame(sample_ph_data, columns=X_train_ph.columns)\n",
        "    predicted_ph = model_ph.predict(sample_ph_data_fixed)[0]\n",
        "    print(f\"Predicted soil pH: {predicted_ph:.2f}\")"
      ],
      "metadata": {
        "id": "8eBhWfP4PaKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYFIOVHKPYWL"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 📦 Setup\n",
        "# ============================================================\n",
        "!pip install -q pandas scikit-learn joblib lightgbm imbalanced-learn\n",
        "\n",
        "import re\n",
        "import math\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "MIN_SAMPLES_PER_CLASS = 10  # more aggressive merging\n",
        "CSV_PATH = \"/content/crop_steps.csv\"\n",
        "\n",
        "# ============================================================\n",
        "# 🧼 Load & Clean\n",
        "# ============================================================\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "df.columns = [c.strip().replace(\" \", \"_\").lower() for c in df.columns]\n",
        "\n",
        "cols_needed = [\n",
        "    \"crop_name\",\"days\",\"stage\",\"irrigation\",\"irrigation_type\",\n",
        "    \"fertilizer_type\",\"fertilizer_dosage\"\n",
        "]\n",
        "for c in cols_needed:\n",
        "    if c not in df.columns:\n",
        "        df[c] = np.nan\n",
        "\n",
        "# Normalize strings, keep NaN\n",
        "for c in [\"crop_name\",\"stage\",\"irrigation\",\"irrigation_type\",\"fertilizer_type\",\"fertilizer_dosage\"]:\n",
        "    df[c] = df[c].apply(lambda x: x.strip().lower() if isinstance(x, str) else np.nan)\n",
        "\n",
        "df[\"days\"] = pd.to_numeric(df[\"days\"], errors=\"coerce\")\n",
        "df = df.dropna(subset=[\"crop_name\",\"days\"]).drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "# ============================================================\n",
        "# 🔤 Stage grouping\n",
        "# ============================================================\n",
        "def map_stage_group(s):\n",
        "    if not isinstance(s, str): return \"other\"\n",
        "    x = s.lower()\n",
        "    if any(k in x for k in [\"harvest\",\"harvesting\",\"harvestable\"]):\n",
        "        return \"harvest\"\n",
        "    if any(k in x for k in [\"maturity\",\"ripen\",\"mature\"]):\n",
        "        return \"maturity\"\n",
        "    if any(k in x for k in [\"flower\",\"bloom\",\"anthesis\",\"tassel\",\"panicl\",\"ear\",\"silk\",\"fruit\",\"pod\",\"boll\",\"grain fill\",\"reproductive\"]):\n",
        "        return \"reproductive\"\n",
        "    if any(k in x for k in [\"sow\",\"seed\",\"nursery\",\"germination\",\"transplant\"]):\n",
        "        return \"sowing\"\n",
        "    if any(k in x for k in [\"veg\",\"tillering\",\"elongation\",\"leaf\",\"stem\",\"v-stage\"]):\n",
        "        return \"vegetative\"\n",
        "    return \"other\"\n",
        "\n",
        "df[\"stage_grouped\"] = df[\"stage\"].apply(map_stage_group)\n",
        "\n",
        "# ============================================================\n",
        "# 🚰 Irrigation type grouping\n",
        "# ============================================================\n",
        "def map_irrigation_type(t):\n",
        "    if not isinstance(t,str): return \"other\"\n",
        "    x = t.lower()\n",
        "    if \"drip\" in x: return \"drip\"\n",
        "    if \"sprinkler\" in x: return \"sprinkler\"\n",
        "    if \"furrow\" in x: return \"furrow\"\n",
        "    if \"flood\" in x or \"basin\" in x or \"surface\" in x: return \"flood\"\n",
        "    if \"rainfed\" in x or \"natural\" in x: return \"rainfed\"\n",
        "    if x in [\"none\",\"-\",\"–\",\"na\",\"n/a\",\"no irrigation\"]: return \"none\"\n",
        "    if any(k in x for k in [\" or \",\"/\"]): return \"mixed\"\n",
        "    return \"other\"\n",
        "\n",
        "df[\"irrigation_type_grouped\"] = df[\"irrigation_type\"].apply(map_irrigation_type)\n",
        "\n",
        "# ============================================================\n",
        "# 🧪 Fertilizer type grouping + dosage\n",
        "# ============================================================\n",
        "def map_fert_type(t):\n",
        "    if not isinstance(t,str): return \"other\"\n",
        "    x = t.lower()\n",
        "    if x in [\"-\",\"–\",\"na\",\"n/a\",\"none\",\"no\",\"no fertilizer\"]: return \"none\"\n",
        "    if \"npk\" in x or \"starter\" in x or \"basal\" in x: return \"npk\"\n",
        "    if \"fym\" in x or \"compost\" in x or \"manure\" in x or \"organic\" in x: return \"organic\"\n",
        "    if \"nitrogen\" in x or re.search(r\"\\bn\\b\", x): return \"nitrogen\"\n",
        "    if \"phosphorus\" in x or re.search(r\"\\bp\\b\", x): return \"phosphorus\"\n",
        "    if \"potassium\" in x or re.search(r\"\\bk\\b\", x): return \"potassium\"\n",
        "    if \"micro\" in x or any(k in x for k in [\"boron\",\"zinc\",\"fe\",\"mn\"]): return \"micronutrients\"\n",
        "    return \"other\"\n",
        "\n",
        "def extract_dosage(s):\n",
        "    if not isinstance(s, str): return (np.nan, \"unknown\")\n",
        "    txt = s.lower()\n",
        "    num_match = re.findall(r\"(\\d+(?:\\.\\d+)?)\\s*(?:-|to|–)\\s*(\\d+(?:\\.\\d+)?)\", txt)\n",
        "    if num_match:\n",
        "        lo, hi = map(float, num_match[0])\n",
        "        amount = (lo + hi) / 2\n",
        "    else:\n",
        "        nums = re.findall(r\"\\d+(?:\\.\\d+)?\", txt)\n",
        "        amount = float(nums[0]) if nums else np.nan\n",
        "    unit = \"unknown\"\n",
        "    if \"per plant\" in txt or \"/ plant\" in txt: unit = \"per plant\"\n",
        "    elif \"per acre\" in txt or \"/ acre\" in txt: unit = \"per acre\"\n",
        "    elif \"per ha\" in txt or \"/ ha\" in txt or \"per hectare\" in txt: unit = \"per ha\"\n",
        "    return (amount, unit)\n",
        "\n",
        "df[\"fertilizer_type_grouped\"] = df[\"fertilizer_type\"].apply(map_fert_type)\n",
        "dos_pairs = df[\"fertilizer_dosage\"].apply(extract_dosage)\n",
        "df[\"fert_dose_amount\"] = [p[0] for p in dos_pairs]\n",
        "df[\"fert_dose_unit\"] = [p[1] for p in dos_pairs]\n",
        "\n",
        "# ============================================================\n",
        "# ⚖️ Merge rare classes\n",
        "# ============================================================\n",
        "def merge_rare(y, min_samples=MIN_SAMPLES_PER_CLASS):\n",
        "    counts = y.value_counts()\n",
        "    rare = set(counts[counts < min_samples].index)\n",
        "    return y.apply(lambda v: v if v not in rare else \"other\")\n",
        "\n",
        "# ============================================================\n",
        "# 🧠 Training helper\n",
        "# ============================================================\n",
        "def train_classifier(X, y, model_name):\n",
        "    y = merge_rare(y)\n",
        "\n",
        "    # Split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",
        "    )\n",
        "\n",
        "    cat_cols = [c for c in X.columns if X[c].dtype == \"object\"]\n",
        "    num_cols = [c for c in X.columns if np.issubdtype(X[c].dtype, np.number)]\n",
        "\n",
        "    # Fill NaNs before SMOTE\n",
        "    X_train_copy = X_train.copy()\n",
        "    for col in cat_cols:\n",
        "        X_train_copy[col] = X_train_copy[col].fillna(\"missing\").astype(\"category\")\n",
        "    for col in num_cols:\n",
        "        X_train_copy[col] = X_train_copy[col].fillna(X_train_copy[col].median())\n",
        "\n",
        "    # Categorical feature indices for SMOTENC\n",
        "    cat_indices = [X_train_copy.columns.get_loc(c) for c in cat_cols]\n",
        "\n",
        "    smote = SMOTENC(categorical_features=cat_indices, random_state=RANDOM_STATE)\n",
        "    X_bal, y_bal = smote.fit_resample(X_train_copy, y_train)\n",
        "\n",
        "    # Pipeline\n",
        "    pre = ColumnTransformer([\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
        "        (\"num\", StandardScaler(), num_cols)\n",
        "    ])\n",
        "\n",
        "    model = LGBMClassifier(\n",
        "        random_state=RANDOM_STATE,\n",
        "        class_weight=\"balanced\",\n",
        "        n_estimators=300,\n",
        "        learning_rate=0.05\n",
        "    )\n",
        "\n",
        "    pipe = Pipeline([(\"pre\", pre), (\"clf\", model)])\n",
        "    pipe.fit(X_bal, y_bal)\n",
        "\n",
        "    preds = pipe.predict(X_test)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    f1m = f1_score(y_test, preds, average=\"macro\")\n",
        "\n",
        "    print(f\"\\n=== {model_name.upper()} ===\")\n",
        "    print(f\"Accuracy: {acc:.3f} | Macro F1: {f1m:.3f}\")\n",
        "    print(classification_report(y_test, preds, zero_division=0))\n",
        "\n",
        "    joblib.dump(pipe, f\"/content/{model_name}_model.joblib\")\n",
        "    print(f\"💾 Saved -> /content/{model_name}_model.joblib\")\n",
        "    return pipe\n",
        "\n",
        "# ============================================================\n",
        "# 1) Irrigation requirement\n",
        "# ============================================================\n",
        "def map_irrig_need(v):\n",
        "    if not isinstance(v,str): return np.nan\n",
        "    x = v.lower().strip()\n",
        "    if x in [\"yes\",\"y\",\"1\",\"true\",\"limited\",\"light\",\"partial\"]: return \"yes\"\n",
        "    if x in [\"no\",\"n\",\"0\",\"false\",\"skip\"]: return \"no\"\n",
        "    return np.nan\n",
        "\n",
        "df[\"irrigation_bin\"] = df[\"irrigation\"].apply(map_irrig_need)\n",
        "df_irri = df.dropna(subset=[\"irrigation_bin\"])\n",
        "irrigation_model = train_classifier(df_irri[[\"crop_name\",\"days\"]], df_irri[\"irrigation_bin\"], \"irrigation_requirement\")\n",
        "\n",
        "# ============================================================\n",
        "# 2) Stage prediction\n",
        "# ============================================================\n",
        "stage_model = train_classifier(df[[\"crop_name\",\"days\",\"fert_dose_amount\"]], df[\"stage_grouped\"], \"stage_prediction\")\n",
        "\n",
        "# ============================================================\n",
        "# 3) Irrigation type\n",
        "# ============================================================\n",
        "irrig_type_model = train_classifier(df[[\"crop_name\",\"days\",\"stage_grouped\"]], df[\"irrigation_type_grouped\"], \"irrigation_type\")\n",
        "\n",
        "# ============================================================\n",
        "# 4) Fertilizer type\n",
        "# ============================================================\n",
        "fert_type_model = train_classifier(df[[\"crop_name\",\"days\",\"stage_grouped\",\"fert_dose_amount\"]], df[\"fertilizer_type_grouped\"], \"fertilizer_type_grouped\")\n",
        "\n",
        "# ============================================================\n",
        "# Dosage table\n",
        "# ============================================================\n",
        "dose_table = df.groupby([\"crop_name\",\"stage_grouped\",\"fertilizer_type_grouped\"], dropna=False)[\"fert_dose_amount\"].median().reset_index().rename(columns={\"fert_dose_amount\":\"median_dose\"})\n",
        "dose_table.to_parquet(\"/content/fertilizer_median_dose_table.parquet\", index=False)\n",
        "\n",
        "print(\"\\n✅ All models trained & saved.\")\n"
      ]
    }
  ]
}